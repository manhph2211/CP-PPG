{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 1024])\n",
      "torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from src.models.model_utils import Conv_block, BLSTM, Up_conv\n",
    "from src.utils.utils import get_config\n",
    "from configs.seed import *\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, cfgs):\n",
    "        super(Generator, self).__init__()\n",
    "        self.cfgs = cfgs\n",
    "        self.depth = self.cfgs['model']['baseline']['depth']\n",
    "        self.use_se_block = self.cfgs['model']['baseline']['use_se_block']\n",
    "        self.initial_features = self.cfgs['model']['baseline']['initial_features']\n",
    "        self.features = [self.initial_features * (2**i) for i in range(self.depth)]    \n",
    "        self.img_ch = self.cfgs['model']['baseline']['chin']\n",
    "        self.output_ch = self.cfgs['model']['baseline']['chout']\n",
    "        self.use_lstm = self.cfgs['model']['baseline']['use_lstm']\n",
    "        self.use_gated_block = self.cfgs['model']['baseline']['use_gated_block']\n",
    "        self.gn_in = self.cfgs['data']['gn_input']\n",
    "        \n",
    "        if self.gn_in: \n",
    "            self.first_gn = nn.GroupNorm(1, 1)\n",
    "            self.film_gn = nn.GroupNorm(1, 1)\n",
    "            self.last_gn = nn.GroupNorm(1, 1)\n",
    "\n",
    "        # Encoding path\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.encoder_films = nn.ModuleList()\n",
    "\n",
    "        self.encoders.append(Conv_block(self.img_ch, self.features[0], use_gated_block=self.use_gated_block, use_se_block=self.use_se_block))\n",
    "        for i in range(1, self.depth):\n",
    "            self.encoders.append(Conv_block(self.features[i-1], self.features[i], use_gated_block=self.use_gated_block, use_se_block=self.use_se_block))\n",
    "\n",
    "        # lstm layer\n",
    "        if self.use_lstm:\n",
    "            self.lstm = BLSTM(self.features[-1], bi = True)\n",
    "\n",
    "        # Decoding path\n",
    "        self.up_convs = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "\n",
    "        for i in range(self.depth-1, -1, -1):\n",
    "            self.up_convs.append(Up_conv(self.features[i], self.features[i-1] if i != 0 else self.features[0], use_gated_block=self.use_gated_block))\n",
    "            in_channels = self.features[i] + (self.features[i-1] if i != 0 else self.features[0])\n",
    "            out_channels = self.features[i-1] if i != 0 else self.initial_features  \n",
    "            self.decoders.append(Conv_block(in_channels, out_channels, use_gated_block=self.use_gated_block, use_se_block=self.use_se_block))\n",
    "\n",
    "        self.Maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "        self.Conv_1x1 = nn.Conv1d(self.features[0], self.output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x, seg_film = None, mask_tensor=None):\n",
    "        skip_connections = []\n",
    "        if self.gn_in:\n",
    "            x = self.first_gn(x)\n",
    "        \n",
    "        # encoding path\n",
    "        for i in range(self.depth):\n",
    "            x = self.encoders[i](x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.Maxpool(x)\n",
    "            x = self.Dropout(x)\n",
    "            \n",
    "        # lstm layer\n",
    "        if self.use_lstm:\n",
    "            x = x.permute(2, 0, 1)\n",
    "            x, _ = self.lstm(x)\n",
    "            x = x.permute(1, 2, 0)\n",
    "\n",
    "        # decoding path\n",
    "        for i in range(self.depth):\n",
    "            x = self.up_convs[i](x)  \n",
    "            x = torch.cat((skip_connections[-(i+1)], x), dim=1)\n",
    "            x = self.Dropout(x)\n",
    "            x = self.decoders[i](x)  \n",
    "\n",
    "        x = self.Conv_1x1(x)\n",
    "        if self.gn_in:\n",
    "            x = self.last_gn(x)\n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, cfgs):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.cfgs = cfgs\n",
    "        self.depth = self.cfgs['model']['baseline']['depth']\n",
    "        self.use_se_block = self.cfgs['model']['baseline']['use_se_block']\n",
    "        self.initial_features = self.cfgs['model']['baseline']['initial_features']\n",
    "        self.features = [self.initial_features * (2**i) for i in range(self.depth)]    \n",
    "        self.img_ch = self.cfgs['model']['baseline']['chin']\n",
    "        self.output_ch = self.cfgs['model']['baseline']['chout']\n",
    "        self.use_lstm = self.cfgs['model']['baseline']['use_lstm']\n",
    "        self.use_gated_block = self.cfgs['model']['baseline']['use_gated_block']\n",
    "        self.gn_input = self.cfgs['data']['gn_input']\n",
    "        self.use_hinge = self.cfgs['train']['hinge']\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "\n",
    "        if self.gn_input:\n",
    "            self.first_gn = nn.GroupNorm(1, 1)\n",
    "\n",
    "        self.encoders.append(Conv_block(self.img_ch, self.features[0], use_gated_block=self.use_gated_block, use_se_block=self.use_se_block))\n",
    "        \n",
    "        for i in range(1, self.depth):\n",
    "            self.encoders.append(Conv_block(self.features[i-1], self.features[i], use_gated_block=self.use_gated_block, use_se_block=self.use_se_block))\n",
    "\n",
    "        self.Maxpool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.Dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "        if self.use_hinge:\n",
    "            self.adv_layer = nn.Sequential(nn.Linear(128 * 128, 1))\n",
    "        else:\n",
    "            self.adv_layer = nn.Sequential(nn.Linear(128 * 128, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.gn_input:\n",
    "            x = self.first_gn(x)\n",
    "            \n",
    "        for i in range(self.depth):\n",
    "            x = self.encoders[i](x)\n",
    "            x = self.Maxpool(x)\n",
    "            x = self.Dropout(x)\n",
    "\n",
    "        out = x.view(x.size(0), -1)\n",
    "        out = self.adv_layer(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfgs = get_config()\n",
    "    model = Generator(cfgs)\n",
    "    x = torch.randn(1, 1, 128 * 8)\n",
    "    out = model(x, x)\n",
    "    print(out.shape)\n",
    "    \n",
    "    model = Discriminator(cfgs)\n",
    "    x = torch.randn(1, 1, 128 * 8)\n",
    "    y = model(x)\n",
    "    print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from src.metrics.metrics import CustomLoss, DisLoss, GenLoss\n",
    "from src.dataloader.dataset import get_loader\n",
    "from src.models.cpppg import Generator, Discriminator\n",
    "# from src.models.model_utils import DiscriminatorV2\n",
    "from src.utils.utils import plot_result, depadding\n",
    "from src.utils.postprocess import moving_average_batch\n",
    "import random\n",
    "from torch.autograd import Variable\n",
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
    "from configs.seed import *\n",
    "\n",
    "\n",
    "class AdversarialTrainer:\n",
    "    def __init__(self, tracking, cfgs):\n",
    "        self.tracking = tracking\n",
    "        self.cfgs = cfgs\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.clip_value = self.cfgs['train']['clip_value']\n",
    "        self.epoch_n = self.cfgs['train']['epoch_n']\n",
    "        self.BEST_LOSS = np.inf\n",
    "        self.ckpt = self.cfgs['train']['ckpt']\n",
    "\n",
    "        self.model = Generator(cfgs).to(self.device)   \n",
    "        self.criterion = CustomLoss(self.cfgs).to(self.device)\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), betas=(0.9, 0.999), weight_decay=0.005, lr=self.cfgs['train']['lr'])\n",
    "        self.discriminator = Discriminator(cfgs).to(self.device)\n",
    "        if self.cfgs['train']['hinge']:\n",
    "            self.gen_loss = GenLoss().to(self.device)\n",
    "            self.discriminator_loss = DisLoss().to(self.device)\n",
    "        else:\n",
    "            self.discriminator_loss = torch.nn.BCELoss().to(self.device) \n",
    "\n",
    "        self.discriminator_optimizer = torch.optim.AdamW(self.discriminator.parameters(), betas=(0.9, 0.999), weight_decay=0.005, lr=self.cfgs['train']['lr']/3)\n",
    "        self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, factor=0.9, patience=8, verbose=True)\n",
    "        self.d_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.discriminator_optimizer, factor=0.9, patience=8, verbose=True)\n",
    "\n",
    "        self.train_loader, self.val_loader, self.test_loader = get_loader(self.cfgs)\n",
    "        # self.load_weights()\n",
    "\n",
    "    def load_weights(self):\n",
    "        try:\n",
    "            self.model.load_state_dict(torch.load(self.ckpt, map_location=self.device))\n",
    "            # self.discriminator.load_state_dict(torch.load(\"checkpoints/discriminator.pth\", map_location=self.device))\n",
    "            print(\"SUCCESSFULLY LOAD TRAINED MODELS !\")\n",
    "        except:\n",
    "            print('FIRST TRAINING')\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        self.discriminator.train()\n",
    "        train_loss_epoch = 0\n",
    "        train_cosin_loss_epoch = 0\n",
    "        train_peak_to_peak_loss = 0\n",
    "        train_mse_loss = 0\n",
    "        theta = 0.1\n",
    "\n",
    "        for src_signal, ref_signal, seg_film, mask in tqdm(self.train_loader):\n",
    "            \n",
    "            src_signal = src_signal.to(self.device)\n",
    "            seg_film = seg_film.to(self.device)\n",
    "            out = self.model(src_signal, seg_film, mask.to(self.device))   \n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            ref_signal = ref_signal.to(self.device)\n",
    "            total_loss, cosin_loss, peak_to_peak_loss, mse_loss = self.criterion(out, ref_signal)\n",
    "            \n",
    "            if self.cfgs['train']['hinge']:\n",
    "                g_loss = self.gen_loss(self.discriminator(out))\n",
    "            else:\n",
    "                g_loss = self.discriminator_loss(self.discriminator(out), Variable(Tensor(src_signal.shape[0], 1).fill_(1.0), requires_grad=False))\n",
    "            \n",
    "            total_loss += theta * g_loss \n",
    "            train_loss_epoch += total_loss.item()\n",
    "            train_cosin_loss_epoch += cosin_loss.item()\n",
    "            train_peak_to_peak_loss += peak_to_peak_loss.item()\n",
    "            train_mse_loss += mse_loss.item()\n",
    "            total_loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            valid = Variable(Tensor(src_signal.shape[0], 1).fill_(1.0), requires_grad=False)\n",
    "            fake = Variable(Tensor(src_signal.shape[0], 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "            self.discriminator_optimizer.zero_grad()\n",
    "            if self.cfgs['train']['hinge']:\n",
    "                d_loss = self.discriminator_loss(self.discriminator(out.detach()), self.discriminator(ref_signal))\n",
    "\n",
    "            else:\n",
    "                real_loss = self.discriminator_loss(self.discriminator(ref_signal), valid)\n",
    "                fake_loss = self.discriminator_loss(self.discriminator(out.detach()), fake)\n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            self.discriminator_optimizer.step()   \n",
    "\n",
    "        return train_loss_epoch/ len(self.train_loader), train_cosin_loss_epoch / len(self.train_loader), train_peak_to_peak_loss/ len(self.train_loader), train_mse_loss / len(self.train_loader)\n",
    "\n",
    "    def val_epoch(self):\n",
    "        self.model.eval()\n",
    "        val_loss_epoch = 0\n",
    "        val_cosin_loss_epoch = 0\n",
    "        val_peak_to_peak_loss = 0\n",
    "        val_mse_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for src_signal, ref_signal, seg_film, mask in tqdm(self.val_loader):\n",
    "                src_signal = src_signal.to(self.device)\n",
    "                seg_film = seg_film.to(self.device)\n",
    "                out = self.model(src_signal, seg_film, mask.to(self.device))\n",
    "                ref_signal = ref_signal.to(self.device)\n",
    "                total_loss, cosin_loss, peak_to_peak_loss, mse_loss = self.criterion(out, ref_signal)\n",
    "                val_loss_epoch += total_loss.item()\n",
    "                self.val_loss_epoch = val_loss_epoch\n",
    "                val_cosin_loss_epoch += cosin_loss.item()\n",
    "                val_peak_to_peak_loss += peak_to_peak_loss.item()\n",
    "                val_mse_loss += mse_loss.item()\n",
    "            return val_loss_epoch / len(self.val_loader), val_cosin_loss_epoch / len(self.val_loader), val_peak_to_peak_loss / len(self.val_loader), val_mse_loss / len(self.val_loader)\n",
    "    \n",
    "    def test_epoch(self):\n",
    "        self.model.eval()\n",
    "        test_loss_epoch = 0\n",
    "        test_cosin_loss_epoch = 0 \n",
    "        test_peak_to_peak_loss = 0\n",
    "        test_mse_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for src_signal, ref_signal, seg_film, mask in tqdm(self.test_loader):\n",
    "                src_signal = src_signal.to(self.device)\n",
    "                seg_film = seg_film.to(self.device)\n",
    "                out = self.model(src_signal, seg_film, mask.to(self.device))\n",
    "                ref_signal = ref_signal.to(self.device)\n",
    "                total_loss, cosin_loss, peak_to_peak_loss, mse_loss = self.criterion(out, ref_signal)\n",
    "                test_loss_epoch += total_loss.item()\n",
    "                test_cosin_loss_epoch += cosin_loss.item()\n",
    "                test_peak_to_peak_loss += peak_to_peak_loss.item()\n",
    "                test_mse_loss += mse_loss.item()\n",
    "            return test_loss_epoch/ len(self.test_loader), test_cosin_loss_epoch / len(self.test_loader), test_peak_to_peak_loss/len(self.test_loader), test_mse_loss /  len(self.test_loader)\n",
    "\n",
    "    def show_result(self, epoch):\n",
    "        random_idx = random.choice(range(60))\n",
    "        src_signal, ref_signal, seg_film, mask = self.test_loader.dataset[random_idx][0], self.test_loader.dataset[random_idx][1], self.test_loader.dataset[random_idx][2], self.test_loader.dataset[random_idx][3]\n",
    "        src_signal = src_signal.unsqueeze(dim=0)\n",
    "        mask = mask.unsqueeze(dim=0)\n",
    "        out = self.model(src_signal.to(self.device), seg_film.unsqueeze(dim=0).to(self.device), mask.to(self.device)) \n",
    "        real_sr_signal = src_signal.clone()\n",
    "        mask = mask.reshape(-1).cpu().detach().numpy()\n",
    "        ref_signal = ref_signal.reshape(-1).cpu().detach().numpy()\n",
    "        plot_result(real_sr_signal.reshape(-1), out.reshape(-1).cpu().detach().numpy(), ref_signal.reshape(-1))     \n",
    "        self.tracking.log_image(image_data=\"src/experiments/results/result.jpg\", name=f\"Result at epoch: {epoch}\")\n",
    "        \n",
    "    def save_checkpoint(self):\n",
    "        if self.val_loss_epoch < self.BEST_LOSS:\n",
    "            self.BEST_LOSS = self.val_loss_epoch\n",
    "            torch.save(self.model.state_dict(), self.ckpt)\n",
    "            # torch.save(self.discriminator.state_dict(), \"checkpoints/discriminator.pth\")\n",
    "            self.tracking.log_model(\"model\", self.ckpt)\n",
    "\n",
    "    def training_experiment(self):\n",
    "        print(\"BEGIN TRAINING ...\")\n",
    "        for epoch in range(1, self.epoch_n+1):\n",
    "            with self.tracking.train():\n",
    "                train_loss_epoch, train_cosin_loss_epoch, peak_to_peak_loss, train_mse_loss = self.train_epoch()\n",
    "                self.tracking.log_metrics({\n",
    "                    \"total loss\": train_loss_epoch,\n",
    "                    \"mse loss\": train_mse_loss,\n",
    "                    \"cosin similarity\": train_cosin_loss_epoch,\n",
    "                    \"peak-to-peak loss\": peak_to_peak_loss\n",
    "                }, epoch=epoch)\n",
    "\n",
    "            with self.tracking.validate():\n",
    "                val_loss_epoch, val_cosin_loss_epoch, peak_to_peak_loss, val_mse_loss = self.val_epoch()\n",
    "                self.scheduler.step(val_loss_epoch)\n",
    "                self.d_scheduler.step(val_loss_epoch)\n",
    "                self.save_checkpoint()\n",
    "                self.tracking.log_metrics({\n",
    "                    \"total loss\": val_loss_epoch,\n",
    "                    \"mse loss\": val_mse_loss,\n",
    "                    \"cosin similarity\": val_cosin_loss_epoch,\n",
    "                    \"peak-to-peak loss\": peak_to_peak_loss\n",
    "                }, epoch=epoch)\n",
    "            \n",
    "            with self.tracking.test():\n",
    "                test_loss_epoch, test_cosin_loss_epoch, test_peak_to_peak_loss, test_mse_loss = self.test_epoch()\n",
    "                self.tracking.log_metrics({\n",
    "                    \"total loss\": test_loss_epoch,\n",
    "                    \"mse loss\": test_mse_loss,\n",
    "                    \"cosin similarity\": test_cosin_loss_epoch,\n",
    "                    \"peak-to-peak loss\": test_peak_to_peak_loss\n",
    "                }, epoch=epoch)\n",
    "\n",
    "            self.show_result(epoch)\n",
    "\n",
    "            print(\"EPOCH: \", epoch, \" - TRAIN_LOSS: \", train_loss_epoch, \" || VAL_LOSS: \", val_loss_epoch, \" || TEST_LOSS: \", test_loss_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet_ml import Experiment\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "from src.utils.utils import get_config\n",
    "from configs.seed import *\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    cfgs = get_config()\n",
    "\n",
    "    with open('configs/experiment_apikey.txt','r') as f:\n",
    "        api_key = f.read()\n",
    "\n",
    "    tracking = Experiment(\n",
    "        api_key = api_key,\n",
    "        project_name = \"PPG Data v2 - Window Based\",\n",
    "        workspace = \"maxph2211\",\n",
    "    )\n",
    "    tracking.log_parameters(cfgs)\n",
    "    trainer = AdversarialTrainer(tracking, cfgs)\n",
    "        \n",
    "    trainer.training_experiment()\n",
    "    print(\"DONE!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
